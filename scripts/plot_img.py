import sys
import os
import re
import json
import time
import requests
import pandas as pd
import mplfinance as mpf
from datetime import datetime, timedelta

# === å‚æ•°æ ¡éªŒ ===
if len(sys.argv) != 3:
    print("Usage: python plot_img.py <trades.json> <output.png>")
    sys.exit(1)

trade_path = sys.argv[1]
# duration_str = sys.argv[2]
output_path = sys.argv[2]


# === å·¥å…·å‡½æ•° ===
def extract_symbol_and_timeframe(path):
    match = re.search(r'([^/]+)_([0-9a-zA-Z]+)', os.path.dirname(path))
    if match:
        return match.group(1).upper(), match.group(2)
    raise ValueError("è·¯å¾„æ ¼å¼é”™è¯¯")

def timeframe_to_minutes(tf):
    unit = tf[-1]
    val = int(tf[:-1])
    if unit == 'm': return val
    elif unit == 'h': return val * 60
    elif unit == 'd': return val * 60 * 24
    raise ValueError(f"Unsupported tf: {tf}")

def get_latest_aligned_time(tf_minutes):
    now = datetime.utcnow().replace(second=0, microsecond=0)
    aligned_minute = (now.minute // tf_minutes) * tf_minutes
    return now.replace(minute=aligned_minute) - timedelta(minutes=tf_minutes)

def get_expected_start_time(timeframe):
    now = datetime.utcnow().replace(second=0, microsecond=0)
    delta_minutes = timeframe_to_minutes(timeframe)
    start_time = now - timedelta(minutes=delta_minutes)
    aligned_minute = (start_time.minute // delta_minutes) * delta_minutes
    return start_time.replace(minute=aligned_minute)


def find_missing_periods(klines_df, expected_start_time, tf_minutes):
    print(tf_minutes)
    # print(f"é¢„æœŸå¼€å§‹æ—¶é—´: {expected_start_time}")
    # print(f"é¢„æœŸç»“æŸæ—¶é—´: {get_latest_aligned_time(15)}")
    klines_df['timestamp'] = pd.to_datetime(klines_df['kline'].apply(lambda k: k['start_time']), unit='ms')
    klines_df = klines_df.sort_values(by='timestamp').set_index('timestamp')
    expected = pd.date_range(start=expected_start_time, end=get_latest_aligned_time(15), freq=f"{15}min")
    print(f"é¢„æœŸæ—¶é—´æ®µ: {len(expected)}")
    return expected.difference(klines_df.index)

def fetch_binance_continuous_klines(pair, interval, start_time, end_time):
    endpoint = 'https://fapi.binance.com/fapi/v1/continuousKlines'
    contract_type = 'PERPETUAL'
    limit = 1500
    result = []

    start_ms = int(start_time.timestamp() * 1000)
    end_ms = int(end_time.timestamp() * 1000)

    while start_ms < end_ms:
        params = {
            'pair': pair.upper(),
            'contractType': contract_type,
            'interval': interval,
            'startTime': start_ms,
            'endTime': min(end_ms, start_ms + limit * 15 * 60 * 1000),
            'limit': limit
        }
        response = requests.get(endpoint, params=params)
        if response.status_code != 200:
            raise Exception(f"Binance API error: {response.text}")
        data = response.json()
        if not data:
            break
        result.extend(data)
        start_ms = data[-1][0] + 15 * 60 * 1000  # è·³è¿‡æœ€åä¸€ä¸ª candle å¼€å§‹æ—¶é—´
        time.sleep(0.3)  # é¿å…è§¦å‘é™é€Ÿ

    return result[:-1]


def group_klines_by_month(klines):
    grouped = {}
    for k in klines:
        ts = pd.to_datetime(k[0], unit='ms')
        key = f"{ts.year}{ts.month:02d}"
        grouped.setdefault(key, []).append(k)
    return grouped

def read_json_lines_safe(path):
    lines = []
    with open(path, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                obj = json.loads(line)
                lines.append(obj)
            except json.JSONDecodeError:
                continue
    return lines

def write_grouped_klines(grouped, symbol):
    for ym, klist in grouped.items():
        path = f"data/kline_data/{symbol.lower()}_15m_{ym}.json"
        if os.path.exists(path):
            existing = read_json_lines_safe(path)  # ğŸ” ä½¿ç”¨é€è¡ŒåŠ è½½
        else:
            existing = []
        # for k in existing:
        #     try:
        #         print(k['kline']['start_time'])
        #     except:
        #         print(k)
        existing_ts = set(k['kline']['start_time'] for k in existing)
        new_data = [k for k in klist if k[0] not in existing_ts]

        # ä»¥ JSONL æ ¼å¼é€è¡Œè¿½åŠ  new_data
        with open(path, 'a') as f:
            for k in new_data:
                obj = {
                    "event": "",
                    "event_time": "",
                    "pair": symbol,
                    "contract_type": "PERPETUAL",
                    "kline": {
                        "start_time": k[0],
                        "end_time": k[6],
                        "interval": "15m",
                        "first_trade_id": None,
                        "last_trade_id": None,
                        "open": k[1],
                        "close": k[4],
                        "high": k[2],
                        "low": k[3],
                        "volume": k[5],
                        "trade_count": k[8],
                        "is_final": True,
                        "quote_asset_volume": k[7],
                        "taker_buy_base_volume": k[9],
                        "taker_buy_quote_volume": k[10],
                        "ignore": k[11]
                    }
                }
                f.write(json.dumps(obj) + '\n')

def list_months_between(start: datetime, end: datetime):
    result = []
    y, m = start.year, start.month
    ey, em = end.year, end.month
    while (y < ey) or (y == ey and m <= em):
        result.append(f"{y}{m:02d}")
        if m == 12:
            y += 1
            m = 1
        else:
            m += 1
    return result



# symbol ç”± trades.json æ–‡ä»¶è·¯å¾„æ¨æ–­
symbol, tf = extract_symbol_and_timeframe(trade_path)  # å¦‚ btcusdt_15m

duration_minutes = timeframe_to_minutes(tf)
expected_start = get_expected_start_time(tf)
expected_end = get_latest_aligned_time(15)
print(f"é¢„æœŸå¼€å§‹æ—¶é—´: {expected_start}")
print(f"é¢„æœŸç»“æŸæ—¶é—´: {expected_end}")

# æ„é€ è¦è¯»å–çš„æœˆä»½é”®
months = list_months_between(expected_start, expected_end)
print(months)
klines_all = []
for ym in months:  # months æ˜¯ ["202505", "202506", ...]
    path = f"data/kline_data/{symbol.lower()}_15m_{ym}.json"
    if os.path.exists(path):
        klines_all.extend(read_json_lines_safe(path))  # æŒ‰è¡Œè¯»å–ï¼Œæ¯è¡Œä¸ºä¸€ä¸ª dict
    else:
        print(f"[warn] æœªæ‰¾åˆ°: {path}")

# è½¬ DataFrameï¼ˆè¿‡æ»¤æ‰é dict / å¼‚å¸¸è¡Œï¼‰
klines = pd.DataFrame([k for k in klines_all if isinstance(k, dict)])
print(f"è¯»å–åˆ° {len(klines)} æ¡ K çº¿æ•°æ®")


missing = find_missing_periods(klines, expected_start, duration_minutes)
print(f"ç¼ºå¤±æ•°æ®æ¡æ•°: {len(missing)}")
print(missing)
if not missing.empty:
    print(f"ç¼ºå¤±æ—¶é—´æ®µï¼š{missing[0]} â†’ {missing[-1]}")
    raw_klines = fetch_binance_continuous_klines(symbol, "15m", missing[0], missing[-1] + timedelta(minutes=15))
    grouped = group_klines_by_month(raw_klines)
    write_grouped_klines(grouped, symbol)
    print(f"å·²è¡¥å…¨ {len(missing)} æ¡è®°å½•")

# === é‡æ–°è¯»å–æ•°æ® ===
klines_all = []
for ym in months:  # months æ˜¯ ["202505", "202506", ...]
    path = f"data/kline_data/{symbol.lower()}_15m_{ym}.json"
    if os.path.exists(path):
        klines_all.extend(read_json_lines_safe(path))  # æŒ‰è¡Œè¯»å–ï¼Œæ¯è¡Œä¸ºä¸€ä¸ª dict
    else:
        print(f"[warn] æœªæ‰¾åˆ°: {path}")

# è½¬ DataFrameï¼ˆè¿‡æ»¤æ‰é dict / å¼‚å¸¸è¡Œï¼‰
klines = pd.DataFrame([k for k in klines_all if isinstance(k, dict)])
print(f"é‡æ–°è¯»å–åˆ° {len(klines)} æ¡ K çº¿æ•°æ®")

# count = 0
# for k in klines.iterrows():
#     count += 1
#     if count > 1:
#         break
#     print(k)
    


# print(klines)
# === å¤„ç† Kçº¿æ•°æ® ===
df = pd.DataFrame([{
    'timestamp': pd.to_datetime(k['kline']['start_time'], unit='ms'),
    'Open': float(k['kline']['open']),
    'High': float(k['kline']['high']),
    'Low': float(k['kline']['low']),
    'Close': float(k['kline']['close']),
    'Volume': float(k['kline']['volume']),
} for row, k in klines.iterrows()])
df.set_index('timestamp', inplace=True)

# === å¤„ç†æˆäº¤æ•°æ® ===
trades = pd.read_json(trade_path)
trades['timestamp'] = pd.to_datetime(trades['event_time'], unit='ms')
trades = trades.sort_values(by='timestamp')
trades['quantity'] = trades['quantity'].astype(float)
trades['signed_qty'] = trades.apply(lambda row: -row['quantity'] if row['is_buyer_maker'] else row['quantity'], axis=1)

# === ç´¯åŠ æ–¹å‘æ€§æˆäº¤é‡ ===
position_series = (
    trades.set_index("timestamp")["signed_qty"]
    .resample("15min")
    .sum()
    .cumsum()
    .ffill()
)

concat = pd.concat([df, position_series.rename("cumsum_signed_qty")], axis=1)
concat['cumsum_signed_qty'] = concat['cumsum_signed_qty'].fillna(method='ffill')
concat = concat.dropna()
print(concat.shape)

# === è‡ªå®šä¹‰å›¾å±‚ï¼šå åŠ  cumulative sum æŠ˜çº¿ ===
apds = [mpf.make_addplot(concat['cumsum_signed_qty'], panel=0, color='blue', secondary_y=True)]

mpf.plot(
    concat[['Open', 'High', 'Low', 'Close', 'Volume']],
    type='candle',
    volume=True,
    style='classic',
    addplot=apds,
    figscale=1.2,
    figratio=(10, 6),
    title=f'[{symbol} - PERP - {tf}] Monitored Cumsum Position',
    savefig=output_path
)
